{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e34248df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import chess\n",
    "import chess.engine\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086e4119",
   "metadata": {},
   "source": [
    "#  Homework2 ML Chess - Author Andrea Serafini mat. 277048\n",
    "\n",
    "Chess is a Turn Based Games where 2 player (or agents) play competively in order to beat the other player.\n",
    "to implement this type of game different data structure and function have been implemented:\n",
    "\n",
    "- Game and Chess Classes\n",
    "- Heuristics and Chess Heuristic classes\n",
    "- Alpha Beta Pruning algorithm\n",
    "- play and data storage functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb4ba9a",
   "metadata": {},
   "source": [
    "### Abstract Class Game\n",
    "\n",
    "This abstract class can be used to implement a chess game instance, it is similar to the problem class used in the puzzle problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f606f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game():\n",
    "\n",
    "    # Return a collection of the allowable moves from this state.\n",
    "    def actions(self, state):    \n",
    "        raise NotImplementedError\n",
    "    \n",
    "    # return a state State' from State and Action \n",
    "    def result(self, state, move):\n",
    "        raise NotImplementedError\n",
    "    # return True if a final state has been reached\n",
    "    def is_terminal(self, state):\n",
    "        return not self.actions(state)\n",
    "    \n",
    "    #return the player of the current turn\n",
    "    def get_player(self, state):\n",
    "        raise NotImplementedError\n",
    "   \n",
    "    #Returns the turn of the player current player    \n",
    "    def get_turn(self, state):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665bb9c1",
   "metadata": {},
   "source": [
    "# Chess Class\n",
    "\n",
    "this class will be used to instantiate a new chess game board. The board is represented by using Forsythâ€“Edwards Notation (FEN) that is a standard notation for describing a particular board position of a chess game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf0e5e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Chess game with python chess library\n",
    "#\n",
    "class Chess(Game):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.initial = chess.Board().fen()\n",
    "        \n",
    "    # Get all possible moveves of the current state    \n",
    "    def actions(self, state):\n",
    "        board = self.get_board(state)\n",
    "        return board.legal_moves\n",
    "    \n",
    "    # get the resulting board after perform an action\n",
    "    def result(self, state, action):\n",
    "        board = self.get_board(state)\n",
    "        board.push(action)\n",
    "        return board.fen()\n",
    "    \n",
    "    # Undo Move\n",
    "    def undo_move(self, state):\n",
    "        board = self.get_board(state)\n",
    "        board.pop()\n",
    "    \n",
    "    # is game in a termianl state?\n",
    "    # example CHECKMATE, SEVENTYFIVEMOVES, STALEMATE or INSUFFICENTMATERIAL\n",
    "    def is_terminal(self, state):\n",
    "        board = self.get_board(state)\n",
    "        outcome = board.outcome();\n",
    "        if (outcome != None):\n",
    "            return True;\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def display(self, state):\n",
    "        board = self.get_board(state)\n",
    "        display(board)\n",
    "    # FEN representation of the board    \n",
    "    def get_board(self, state):\n",
    "        return chess.Board(state)  \n",
    "    # Return Current Player\n",
    "    def get_player(self, state):\n",
    "        board = self.get_board(state)\n",
    "        return 'White' if board.turn else 'Black'\n",
    "    # Return Turn\n",
    "    def get_turn(self, state):\n",
    "        return self.get_board(state).turn\n",
    "   \n",
    "    # Transform a string to a Move object example c3c5 \n",
    "    def get_move(self, move_str):\n",
    "        move = None\n",
    "        if len(move_str) == 4 or len(move_str) == 5:\n",
    "            try:\n",
    "                move = chess.Move.from_uci(move_str)\n",
    "            except ValueError:\n",
    "                move = None\n",
    "                # do nothing\n",
    "        return move"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13ab474",
   "metadata": {},
   "source": [
    "# Abstract Class Heuristic\n",
    "\n",
    "This abstract class has to be implemented to define the heuristic evaluation for a particular game. All logic related to the evaluation should be defined here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0694b17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Heuristics():\n",
    "    \n",
    "    # at least one heuristic must be mandatory \n",
    "    def h1(self, state):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366c2e74",
   "metadata": {},
   "source": [
    "# ChessHeuristics\n",
    "\n",
    "This class implements the absract class Heuristics. The class is initialized with the value and the weights of the board pieces and their position.  a numpy array is used to balance the weights of each heuristics.\n",
    "The following heuristic have been used:\n",
    "- Check Mate: give a big reward if the move is check mate\n",
    "- Check: give a big reward if the move is check.\n",
    "- White Peces: evaluete the white pieces\n",
    "- Black Peces: evaluete the black pieces\n",
    "- Board: Evaluete the board\n",
    "- Random: add a random component, the idea is to avoid the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0a7389a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessHeuristics(Heuristics):\n",
    "\n",
    "    \n",
    "    def __init__(self):\n",
    "        #heuristics weights\n",
    "        self.weights = np.array([0, 3,3, 0.01, 0])\n",
    "        #piece values\n",
    "        self.pieces_value = {\n",
    "            'p': 100, 'P': 100,\n",
    "            'n': 280, 'N': 280,\n",
    "            'b': 320, 'B': 320,\n",
    "            'r': 479, 'R': 479,\n",
    "            'q': 929, 'Q': 929,\n",
    "            'k': 60000, 'K': 60000,\n",
    "        }\n",
    "        # pieces position evaluations\n",
    "        self.squares_value = {\n",
    "            'P': (  0,   0,   0,   0,   0,   0,   0,   0,\n",
    "                    -31,   8,  -7, -37, -36, -14,   3, -31,\n",
    "                    -22,   9,   5, -11, -10,  -2,   3, -19,\n",
    "                    -26,   3,  10,   9,   6,   1,   0, -23,\n",
    "                    -17,  16,  -2,  15,  14,   0,  15, -13,\n",
    "                    7,  29,  21,  44,  40,  31,  44,   7,\n",
    "                    78,  83,  86,  73, 102,  82,  85,  90,\n",
    "                    0,   0,   0,   0,   0,   0,   0,   0),\n",
    "\n",
    "            'N': (  -74, -23, -26, -24, -19, -35, -22, -69,\n",
    "                    -23, -15,   2,   0,   2,   0, -23, -20,\n",
    "                    -18,  10,  13,  22,  18,  15,  11, -14,\n",
    "                    -1,   5,  31,  21,  22,  35,   2,   0,\n",
    "                    24,  24,  45,  37,  33,  41,  25,  17,\n",
    "                    10,  67,   1,  74,  73,  27,  62,  -2,\n",
    "                    -3,  -6, 100, -36,   4,  62,  -4, -14,\n",
    "                    -66, -53, -75, -75, -10, -55, -58, -70),\n",
    "\n",
    "            'B': (  -7,   2, -15, -12, -14, -15, -10, -10,\n",
    "                    19,  20,  11,   6,   7,   6,  20,  16,\n",
    "                    14,  25,  24,  15,   8,  25,  20,  15,\n",
    "                    13,  10,  17,  23,  17,  16,   0,   7,\n",
    "                    25,  17,  20,  34,  26,  25,  15,  10,\n",
    "                    -9,  39, -32,  41,  52, -10,  28, -14,\n",
    "                    -11,  20,  35, -42, -39,  31,   2, -22,\n",
    "                    -59, -78, -82, -76, -23,-107, -37, -50),\n",
    "\n",
    "            'R': (  -30, -24, -18,   5,  -2, -18, -31, -32,\n",
    "                    -53, -38, -31, -26, -29, -43, -44, -53,\n",
    "                    -42, -28, -42, -25, -25, -35, -26, -46,\n",
    "                    -28, -35, -16, -21, -13, -29, -46, -30,\n",
    "                    0,   5,  16,  13,  18,  -4,  -9,  -6,\n",
    "                    19,  35,  28,  33,  45,  27,  25,  15,\n",
    "                    55,  29,  56,  67,  55,  62,  34,  60,\n",
    "                    35,  29,  33,   4,  37,  33,  56,  50),\n",
    "\n",
    "            'Q': (  -39, -30, -31, -13, -31, -36, -34, -42,\n",
    "                    -36, -18,   0, -19, -15, -15, -21, -38,\n",
    "                    -30,  -6, -13, -11, -16, -11, -16, -27,\n",
    "                    -14, -15,  -2,  -5,  -1, -10, -20, -22,\n",
    "                    1, -16,  22,  17,  25,  20, -13,  -6,\n",
    "                    -2,  43,  32,  60,  72,  63,  43,   2,\n",
    "                    14,  32,  60, -10,  20,  76,  57,  24,\n",
    "                    6,   1,  -8,-104,  69,  24,  88,  26),\n",
    "\n",
    "            'K': (  17,  30,  -3, -14,   6,  -1,  40,  18,\n",
    "                    -4,   3, -14, -50, -57, -18,  13,   4,\n",
    "                    -47, -42, -43, -79, -64, -32, -29, -32,\n",
    "                    -55, -43, -52, -28, -51, -47,  -8, -50,\n",
    "                    -55,  50,  11,  -4, -19,  13,   0, -49,\n",
    "                    -62,  12, -57,  44, -67,  28,  37, -31,\n",
    "                    -32,  10,  55,  56,  56,  55,  10,   3,\n",
    "                    4,  54,  47, -99, -99,  60,  83, -62),\n",
    "\n",
    "            'p': (   0,   0,   0,   0,   0,   0,   0,   0,\n",
    "                    78,  83,  86,  73, 102,  82,  85,  90,\n",
    "                     7,  29,  21,  44,  40,  31,  44,   7,\n",
    "                   -17,  16,  -2,  15,  14,   0,  15, -13,\n",
    "                   -26,   3,  10,   9,   6,   1,   0, -23,\n",
    "                   -22,   9,   5, -11, -10,  -2,   3, -19,\n",
    "                   -31,   8,  -7, -37, -36, -14,   3, -31,\n",
    "                     0,   0,   0,   0,   0,   0,   0,   0),\n",
    "\n",
    "            'n': ( -66, -53, -75, -75, -10, -55, -58, -70,\n",
    "                    -3,  -6, 100, -36,   4,  62,  -4, -14,\n",
    "                    10,  67,   1,  74,  73,  27,  62,  -2,\n",
    "                    24,  24,  45,  37,  33,  41,  25,  17,\n",
    "                    -1,   5,  31,  21,  22,  35,   2,   0,\n",
    "                   -18,  10,  13,  22,  18,  15,  11, -14,\n",
    "                   -23, -15,   2,   0,   2,   0, -23, -20,\n",
    "                   -74, -23, -26, -24, -19, -35, -22, -69),\n",
    "\n",
    "            'b': ( -59, -78, -82, -76, -23,-107, -37, -50,\n",
    "                   -11,  20,  35, -42, -39,  31,   2, -22,\n",
    "                    -9,  39, -32,  41,  52, -10,  28, -14,\n",
    "                    25,  17,  20,  34,  26,  25,  15,  10,\n",
    "                    13,  10,  17,  23,  17,  16,   0,   7,\n",
    "                    14,  25,  24,  15,   8,  25,  20,  15,\n",
    "                    19,  20,  11,   6,   7,   6,  20,  16,\n",
    "                    -7,   2, -15, -12, -14, -15, -10, -10),\n",
    "\n",
    "            'r': (  35,  29,  33,   4,  37,  33,  56,  50,\n",
    "                    55,  29,  56,  67,  55,  62,  34,  60,\n",
    "                    19,  35,  28,  33,  45,  27,  25,  15,\n",
    "                     0,   5,  16,  13,  18,  -4,  -9,  -6,\n",
    "                   -28, -35, -16, -21, -13, -29, -46, -30,\n",
    "                   -42, -28, -42, -25, -25, -35, -26, -46,\n",
    "                   -53, -38, -31, -26, -29, -43, -44, -53,\n",
    "                   -30, -24, -18,   5,  -2, -18, -31, -32),\n",
    "\n",
    "            'q': (   6,   1,  -8,-104,  69,  24,  88,  26,\n",
    "                    14,  32,  60, -10,  20,  76,  57,  24,\n",
    "                    -2,  43,  32,  60,  72,  63,  43,   2,\n",
    "                     1, -16,  22,  17,  25,  20, -13,  -6,\n",
    "                   -14, -15,  -2,  -5,  -1, -10, -20, -22,\n",
    "                   -30,  -6, -13, -11, -16, -11, -16, -27,\n",
    "                   -36, -18,   0, -19, -15, -15, -21, -38,\n",
    "                   -39, -30, -31, -13, -31, -36, -34, -42),\n",
    "\n",
    "            'k': (   4,  54,  47, -99, -99,  60,  83, -62,\n",
    "                   -32,  10,  55,  56,  56,  55,  10,   3,\n",
    "                   -62,  12, -57,  44, -67,  28,  37, -31,\n",
    "                   -55,  50,  11,  -4, -19,  13,   0, -49,\n",
    "                   -55, -43, -52, -28, -51, -47,  -8, -50,\n",
    "                   -47, -42, -43, -79, -64, -32, -29, -32,\n",
    "                    -4,   3, -14, -50, -57, -18,  13,   4,\n",
    "                    17,  30,  -3, -14,   6,  -1,  40,  18)}\n",
    "        \n",
    "\n",
    "    #give big bonus on Check Mate\n",
    "    def check_mate(self, board):\n",
    "        value = 0;\n",
    "        if (board.is_checkmate()):\n",
    "            value += 99999\n",
    "        return value\n",
    "    #give a bonus on check moves\n",
    "    def check(self, board):\n",
    "        value = 0;\n",
    "        if (board.is_check()):\n",
    "            value += 1000\n",
    "        return value\n",
    "    \n",
    "    # evaluate the pieces on the board \n",
    "    def pieces(self, board):\n",
    "        value_black = 0\n",
    "        value_white = 0       \n",
    "        pieces = board.piece_map()       \n",
    "        for p in pieces:\n",
    "            if(str(pieces[p]).isupper()):\n",
    "                value_black += self.pieces_value[str(pieces[p])]\n",
    "            else:\n",
    "                value_white += self.pieces_value[str(pieces[p])]\n",
    "        return value_black if board.turn else value_white \n",
    "    \n",
    "    \n",
    "    # number of pieces\n",
    "    def player_pieces(self, board):\n",
    "        value = len(board.piece_map()) \n",
    "        return - value\n",
    "    \n",
    "    # evaluate the pieces on the board \n",
    "    def board(self, board):\n",
    "        value_black = 0\n",
    "        value_white = 0       \n",
    "        pieces = board.piece_map()       \n",
    "        for p in pieces:\n",
    "            if(str(pieces[p]).isupper()):\n",
    "                value_black += self.squares_value[str(pieces[p])][p]\n",
    "            else:\n",
    "                value_white += self.squares_value[str(pieces[p])][p]\n",
    " \n",
    "        return value_black if board.turn else value_white \n",
    "    \n",
    "    # add a Random Pick component on the global heuristics, this will be useful in case the evaluation of the other \n",
    "    # heuristic is the same for both players\n",
    "    def random(self, board):\n",
    "        bonus = round(random.random(), 1)*10\n",
    "        return bonus\n",
    "    \n",
    "    #Linear Combination of the heuristics\n",
    "    def h(self, game, state): \n",
    "        b = game.get_board(state)\n",
    "        h = np.array([self.random(b), self.check_mate(b), self.check(b), self.pieces(b), self.board(b)])\n",
    "        lc = self.weights * h\n",
    "        #debug print\n",
    "        #print ('W_Heuristic_Array:'+ str(lc) )\n",
    "        #print ('H_VALUE:'+ str(round(lc.sum(), 4)) )\n",
    "        return round(lc.sum(), 4)\n",
    "    \n",
    "    def h_as_arr(self, game, state):\n",
    "        b = game.get_board(state)\n",
    "        h = np.array([self.random(b), self.check_mate(b), self.check(b), self.pieces(b), self.board(b)])\n",
    "        return np.around(self.weights * h, decimals=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56088ca6",
   "metadata": {},
   "source": [
    "# Alpha-Beta Pruning\n",
    "\n",
    "This is the classic Minimax algorithm with alpha beta pruning in this version you can set the depth parameter in order to visite more or less states of the game before perform the move. The evaluation ins performed using the chess heuristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b79141c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_beta_pruning (game,heuristics, state, depth, alpha, beta, max_player):\n",
    "    if depth == 0 or game.is_terminal(state):\n",
    "        return heuristics.h(game,state)\n",
    "    \n",
    "    if max_player:\n",
    "        max_ev = -np.inf\n",
    "        for move in game.actions(state):\n",
    "            new_state = game.result(state,move)\n",
    "            ev = alpha_beta_pruning(game,heuristics, new_state, depth-1, alpha, beta, False)\n",
    "            max_ev = max(max_ev, ev)\n",
    "            alpha = max(alpha, ev)\n",
    "            if beta<= alpha:\n",
    "                break\n",
    "        \n",
    "        return max_ev\n",
    "    if not max_player:\n",
    "        min_ev = np.inf\n",
    "        for move in game.actions(state):\n",
    "            new_state = game.result(state, move)\n",
    "            ev = alpha_beta_pruning(game,heuristics, new_state, depth-1, alpha, beta, True)\n",
    "            min_ev = min(min_ev, ev)\n",
    "            beta = min(beta, ev)\n",
    "            if beta <= alpha:\n",
    "                break\n",
    "        return min_ev\n",
    "\n",
    "def get_best_move(game, state,depth,max_player):\n",
    "    max_move = None\n",
    "    max_eval = -np.inf\n",
    "    heuristics=ChessHeuristics()\n",
    "    for move in game.actions(state):\n",
    "        new_state = game.result(state, move)\n",
    "        ev = alpha_beta_pruning(game,heuristics, new_state, depth - 1, -np.inf, np.inf, False)\n",
    "        #Save moves for predictive data\n",
    "        #if player != 'White':\n",
    "        save_heuristic_score(game.get_board(state), ev,game.get_player(state))\n",
    "        if ev > max_eval:\n",
    "            max_eval = ev\n",
    "            max_move = move\n",
    "    #print ('BEST MOVE' + str (max_eval)+' PLAYER'+str (game.get_player(state)))      \n",
    "    return max_eval, max_move\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5c5063",
   "metadata": {},
   "source": [
    "# DataFrame generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8bd2ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Infrastructure to collect data from a number of chess games\n",
    "#\n",
    "def generate_df_row(depth_white,depth_black, final_board, time, moves_number):\n",
    "    winner = final_board.outcome().winner\n",
    "    winner_player = None\n",
    "    if (winner == True):\n",
    "        winner_player = 'White'\n",
    "    if (winner == False):\n",
    "        winner_player = 'Black'\n",
    "    \n",
    "    row = {'White_Depth': depth_white,\n",
    "           'Black_Depth': depth_black,\n",
    "           'final_state': final_board.fen(),\n",
    "           'winner': winner_player,\n",
    "           'termination': final_board.outcome().termination,\n",
    "           'game_time(s)': f'{time:.2f}',\n",
    "           'total_moves': moves_number}\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4c0b21",
   "metadata": {},
   "source": [
    "# Play Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b71dc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Infrastructure for see the agents playing\n",
    "#\n",
    "def play_game_live(game,depth_white=1,depth_black=1, verbose=False ):\n",
    "    state = game.initial\n",
    "    game.display(state)\n",
    "    while not game.is_terminal(state):\n",
    "        player_name = game.get_player(state)\n",
    "        print(\"Player <{}> is thinking...\".format(player_name))\n",
    "        if game.get_player(state)== 'White':\n",
    "            v,move = get_best_move(game, state,depth_white,game.get_player(state))\n",
    "        else: \n",
    "            v,move = get_best_move(game, state,depth_black,game.get_player(state))\n",
    "        state = game.result(state, move)\n",
    "        if verbose: \n",
    "            clear_output(wait=True)\n",
    "            game.display(state)\n",
    "            print(\"Player <{}> choosed the move: {} with a value of {}\".format(player_name, move, v))\n",
    "            print(str(game.get_board(state).outcome()))\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71de146",
   "metadata": {},
   "source": [
    "# SAVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c30d6b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "from chess import SQUARE_NAMES\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14476b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_board_values(board):\n",
    "    sample = []\n",
    "    for i in range(64):\n",
    "        piece = board.piece_at(i)\n",
    "        sample.append((piece.piece_type if piece.color else -piece.piece_type) if piece is not None else 0)\n",
    "\n",
    "    return sample\n",
    "\n",
    "def save_heuristic_score(state, value, color): \n",
    "    board_values = get_board_values(state)\n",
    "    df = pd.DataFrame([board_values + [value]+[color]], columns=[*SQUARE_NAMES, 'score',['is_player_white']])\n",
    "    df.to_csv('data13.csv', mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51e32797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_chess_games(game, depth_white,depth_black, games_number=50, update=False, verbose=True):    \n",
    "    outcome_list = []\n",
    "    for i in range(games_number):\n",
    "        \n",
    "        moves_number = 0\n",
    "        t0 = time.time()\n",
    "        state = game.initial\n",
    "        if (verbose):\n",
    "            print(f'Game {i} started')        \n",
    "        while not game.is_terminal(state):\n",
    "            player = game.get_player(state)\n",
    "            if game.get_player(state)== 'White':\n",
    "                v,move = get_best_move(game, state,depth_white,game.get_player(state))\n",
    "            else:\n",
    "                v,move = get_best_move(game, state,depth_black,game.get_player(state))\n",
    "            state = game.result(state, move)\n",
    "            moves_number += 1\n",
    "\n",
    "        final_board = game.get_board(state)       \n",
    "        t1 = time.time() - t0\n",
    "        outcome_row = generate_df_row(depth_white,depth_black, final_board, t1, moves_number)\n",
    "        outcome_list.append(outcome_row)\n",
    "\n",
    "        if (verbose):\n",
    "            print(f'Game {i} ended in {t1:.2f}s: {final_board.outcome()}')\n",
    "            print('\\n')\n",
    "            #debug print\n",
    "            #print(game.is_terminal(state))\n",
    "        \n",
    "        if (update):\n",
    "            update_dataset()     \n",
    "    return outcome_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c21d3187",
   "metadata": {},
   "outputs": [],
   "source": [
    "#result = play_game_live(Chess(), depth_white = 1,depth_black =1,  verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89173cab",
   "metadata": {},
   "source": [
    "# Heuristic and Algorithm Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ca58ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "#result = play_chess_games(Chess(), depth_white=1, depth_black=3, games_number=20, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db89bcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.DataFrame(result)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80ae907a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = play_chess_games(Chess(), depth_white=2, depth_black=2, games_number=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07ef2d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(result)\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893c4cc7",
   "metadata": {},
   "source": [
    "# Homework 2 Predictive Min-Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9f6447b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_model(color= 'Black'):\n",
    "    \n",
    "    df = pd.read_csv('data.csv', index_col=[0], names=[*SQUARE_NAMES, 'score','player'])\n",
    "\n",
    "    df = df[df['player'] == color].drop('player', axis=1) # removes opponent's matches\n",
    "\n",
    "    df_no_duplicates = df.drop_duplicates()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df_no_duplicates.drop(columns='score'),\n",
    "        df_no_duplicates['score']\n",
    "    )\n",
    "\n",
    "    model = MLPRegressor(max_iter=500,hidden_layer_sizes=(len(SQUARE_NAMES), len(SQUARE_NAMES), len(SQUARE_NAMES)))\n",
    "    \n",
    "\n",
    "    return model.fit(X_train.values, y_train)\n",
    "\n",
    "\n",
    "\n",
    "def get_stored_moves(game,state,model):\n",
    "    prediced_moves = []\n",
    "    for move in game.actions(state):\n",
    "        new_state = game.result(state, move)\n",
    "        values = get_board_values(game.get_board(state))\n",
    "        pre = np.array(values).reshape(-1,64)\n",
    "        value_p = model.predict(pre)\n",
    "        prediced_moves.append((move, value_p))\n",
    "    best_moves = sorted(prediced_moves, key=lambda x: x[1])[-10:] # sublist with the 10 best move and value\n",
    "    return [best_moves[i][0] for i in range(len(best_moves))] # return a list with only moves\n",
    "\n",
    "def get_predictive_move(game, state,depth,max_player, model):\n",
    "    max_move = None\n",
    "    max_eval = -np.inf\n",
    "    heuristics=ChessHeuristics()\n",
    "    for move in get_stored_moves(game,state,model):\n",
    "        new_state = game.result(state, move)\n",
    "        ev = alpha_beta_pruning(game,heuristics, new_state, depth - 1, -np.inf, np.inf, False)\n",
    "        if ev > max_eval:\n",
    "            max_eval = ev\n",
    "            max_move = move\n",
    "    #print ('BEST MOVE' + str (max_eval)+' PLAYER'+str (game.get_player(state)))      \n",
    "    return max_eval, max_move\n",
    "\n",
    "\n",
    "def predictive_alpha_beta (game,heuristics, state, depth, alpha, beta, max_player):\n",
    "    if depth == 0 or game.is_terminal(state):\n",
    "        return heuristics.h(game,state)\n",
    "    \n",
    "    if max_player:\n",
    "        max_ev = -np.inf\n",
    "        for move in game.actions(state):\n",
    "            new_state = game.result(state,move)\n",
    "            ev = alpha_beta_pruning(game,heuristics, new_state, depth-1, alpha, beta, False)\n",
    "            max_ev = max(max_ev, ev)\n",
    "            alpha = max(alpha, ev)\n",
    "            if beta<= alpha:\n",
    "                break\n",
    "        \n",
    "        return max_ev\n",
    "    if not max_player:\n",
    "        min_ev = np.inf\n",
    "        for move in game.actions(state):\n",
    "            new_state = game.result(state, move)\n",
    "            ev = alpha_beta_pruning(game,heuristics, new_state, depth-1, alpha, beta, True)\n",
    "            min_ev = min(min_ev, ev)\n",
    "            beta = min(beta, ev)\n",
    "            if beta <= alpha:\n",
    "                break\n",
    "        return min_ev\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08618fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predictive_chess_games(game, depth_white,depth_black, games_number=50, update=False, verbose=True, model=''):    \n",
    "    outcome_list = []\n",
    "\n",
    "    for i in range(games_number):\n",
    "        \n",
    "        moves_number = 0\n",
    "        t0 = time.time()\n",
    "        state = game.initial\n",
    "        if (verbose):\n",
    "            print(f'Game {i} started')        \n",
    "        while not game.is_terminal(state):\n",
    "            player = game.get_player(state)\n",
    "            if game.get_player(state)== 'White':\n",
    "                #v,move = get_predictive_move(game, state,depth,max_player, model)\n",
    "                v,move = get_best_move(game, state,depth_white,game.get_player(state))\n",
    "            else:\n",
    "                v,move = get_predictive_move(game, state,depth_black,game.get_player(state), model)\n",
    "                #v,move = get_best_move(game, state,depth_black,game.get_player(state))\n",
    "            state = game.result(state, move)\n",
    "            moves_number += 1\n",
    "\n",
    "        final_board = game.get_board(state)       \n",
    "        t1 = time.time() - t0\n",
    "        outcome_row = generate_df_row(depth_white,depth_black, final_board, t1, moves_number)\n",
    "        outcome_list.append(outcome_row)\n",
    "\n",
    "        if (verbose):\n",
    "            print(f'Game {i} ended in {t1:.2f}s: {final_board.outcome()}')\n",
    "            print('\\n')\n",
    "            #debug print\n",
    "            #print(game.is_terminal(state))\n",
    "        \n",
    "        if (update):\n",
    "            update_dataset()     \n",
    "    return outcome_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f2ba39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Skynetth\\.conda\\envs\\artificial_intelligence\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mod =  load_model(\"Black\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "207e6414",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predictive_chess_games(Chess(), depth_white\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,depth_black\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, games_number\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, update\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, model\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "predictive_chess_games(Chess(), depth_white=1,depth_black=3, games_number=1, update=False, verbose=True, mod=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd826e8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
